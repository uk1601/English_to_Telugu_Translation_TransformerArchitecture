{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Translation using Transformer Architecture: English to Telugu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "The objective of this project is to develop a neural machine translation model using the Transformer architecture. The model is trained to translate text from English to another language, leveraging advanced techniques such as attention mechanisms and positional encoding to improve translation accuracy and efficiency.\n",
    "\n",
    "**`Note:`** Trained the Transformer Model from Scratch, experimented with different hyperparameters, and found that the below hyperparameters are the best in so far experiments. For Inference, along with **Greedy Search**, the **Beam-Search** (beam-width is the hyperparameter used to select top-k predicted tokens) was implemented.\n",
    "\n",
    "* Hyperparameters:\n",
    "\n",
    "    * embedding_dim = 256          # dimensionality of the embeddings used for tokens in the input and target sequences\n",
    "    * fully_connected_dim = 512    # dimensionality of the hidden layer of the feedforward neural network within the Transformer block\n",
    "    * num_layers = 4               # number of Transformer blocks in the encoder and decoder stacks\n",
    "    * num_heads = 8                # number of heads in the multi-head attention mechanism\n",
    "    * dropout_rate = 0.1           # dropout rate for regularization\n",
    "\n",
    "    * input_vocab_size = 20394    \n",
    "    * target_vocab_size = 32926   \n",
    "\n",
    "    * max_positional_encoding_input = 20394    # maximum positional encoding value for input sequence\n",
    "    * max_positional_encoding_target = 32926  # maximum positional encoding value for target sequence\n",
    "\n",
    "    * EPOCHS = 120\n",
    "    * batch_size = 32\n",
    "\n",
    "    * MAX_LEN = 325\n",
    "\n",
    "## Steps Involved\n",
    "1. Data Preparation\n",
    "2. Model Architecture\n",
    "3. Training\n",
    "4. Translation Methods\n",
    "5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:24:32.599182Z",
     "iopub.status.busy": "2024-04-03T04:24:32.598862Z",
     "iopub.status.idle": "2024-04-03T04:24:45.743001Z",
     "shell.execute_reply": "2024-04-03T04:24:45.741962Z",
     "shell.execute_reply.started": "2024-04-03T04:24:32.599158Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 04:24:35.182529: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-03 04:24:35.182666: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-03 04:24:35.304904: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import os \n",
    "\n",
    "# from wordcloud import WordCloud\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, Dense, Input, Dropout, LayerNormalization\n",
    "\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:24:46.260191Z",
     "iopub.status.busy": "2024-04-03T04:24:46.259551Z",
     "iopub.status.idle": "2024-04-03T04:24:49.932856Z",
     "shell.execute_reply": "2024-04-03T04:24:49.932113Z",
     "shell.execute_reply.started": "2024-04-03T04:24:46.260160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>telugu_instruction</th>\n",
       "      <th>output</th>\n",
       "      <th>telugu_output</th>\n",
       "      <th>instruction_len</th>\n",
       "      <th>output_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Give three tips for staying healthy.</td>\n",
       "      <td>ఆరోగ్యంగా ఉండటానికి మూడు చిట్కాలు ఇవ్వండి.</td>\n",
       "      <td>1. Eat a balanced and nutritious diet: Make su...</td>\n",
       "      <td>1. సమతుల్య మరియు పోషకమైన ఆహారం తినండి: మీ భోజన...</td>\n",
       "      <td>6</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the three primary colors?</td>\n",
       "      <td>మూడు ప్రాధమిక రంగులు ఏమిటి?</td>\n",
       "      <td>The three primary colors are red, blue, and ye...</td>\n",
       "      <td>మూడు ప్రాధమిక రంగులు ఎరుపు, నీలం మరియు పసుపు. ...</td>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Describe the structure of an atom.</td>\n",
       "      <td>పరమాణువు నిర్మాణాన్ని వివరించండి.</td>\n",
       "      <td>An atom is the basic building block of all mat...</td>\n",
       "      <td>పరమాణువు అనేది అన్ని పదార్ధాల యొక్క ప్రాథమిక బ...</td>\n",
       "      <td>6</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can we reduce air pollution?</td>\n",
       "      <td>వాయు కాలుష్యాన్ని ఎలా తగ్గించవచ్చు?</td>\n",
       "      <td>There are several ways to reduce air pollution...</td>\n",
       "      <td>వాయు కాలుష్యాన్ని తగ్గించడానికి అనేక మార్గాలు ...</td>\n",
       "      <td>6</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pretend you are a project manager of a constru...</td>\n",
       "      <td>మీరు ఒక కన్ స్ట్రక్షన్ కంపెనీలో ప్రాజెక్ట్ మేన...</td>\n",
       "      <td>I had to make a difficult decision when I was ...</td>\n",
       "      <td>ఓ కన్ స్ట్రక్షన్ కంపెనీలో ప్రాజెక్ట్ మేనేజర్ గ...</td>\n",
       "      <td>21</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0               Give three tips for staying healthy.   \n",
       "1                 What are the three primary colors?   \n",
       "2                 Describe the structure of an atom.   \n",
       "3                   How can we reduce air pollution?   \n",
       "4  Pretend you are a project manager of a constru...   \n",
       "\n",
       "                                  telugu_instruction  \\\n",
       "0         ఆరోగ్యంగా ఉండటానికి మూడు చిట్కాలు ఇవ్వండి.   \n",
       "1                        మూడు ప్రాధమిక రంగులు ఏమిటి?   \n",
       "2                  పరమాణువు నిర్మాణాన్ని వివరించండి.   \n",
       "3                వాయు కాలుష్యాన్ని ఎలా తగ్గించవచ్చు?   \n",
       "4  మీరు ఒక కన్ స్ట్రక్షన్ కంపెనీలో ప్రాజెక్ట్ మేన...   \n",
       "\n",
       "                                              output  \\\n",
       "0  1. Eat a balanced and nutritious diet: Make su...   \n",
       "1  The three primary colors are red, blue, and ye...   \n",
       "2  An atom is the basic building block of all mat...   \n",
       "3  There are several ways to reduce air pollution...   \n",
       "4  I had to make a difficult decision when I was ...   \n",
       "\n",
       "                                       telugu_output  instruction_len  \\\n",
       "0  1. సమతుల్య మరియు పోషకమైన ఆహారం తినండి: మీ భోజన...                6   \n",
       "1  మూడు ప్రాధమిక రంగులు ఎరుపు, నీలం మరియు పసుపు. ...                6   \n",
       "2  పరమాణువు అనేది అన్ని పదార్ధాల యొక్క ప్రాథమిక బ...                6   \n",
       "3  వాయు కాలుష్యాన్ని తగ్గించడానికి అనేక మార్గాలు ...                6   \n",
       "4  ఓ కన్ స్ట్రక్షన్ కంపెనీలో ప్రాజెక్ట్ మేనేజర్ గ...               21   \n",
       "\n",
       "   output_len  \n",
       "0         121  \n",
       "1          53  \n",
       "2         209  \n",
       "3         216  \n",
       "4         133  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = \"input/telugu-english-translation-alpaca/yahma_alpaca_cleaned_telugu_filtered_and_romanized.csv\"\n",
    "\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "cols = [\"instruction\", \"telugu_instruction\", \"output\", \"telugu_output\"]\n",
    "df = df[cols]\n",
    "df['instruction_len'] = df['instruction'].apply(lambda x: len(x.split()))\n",
    "df['output_len'] = df[\"output\"].apply(lambda x: len(x.split()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:24:52.539387Z",
     "iopub.status.busy": "2024-04-03T04:24:52.538648Z",
     "iopub.status.idle": "2024-04-03T04:25:05.552565Z",
     "shell.execute_reply": "2024-04-03T04:25:05.551696Z",
     "shell.execute_reply.started": "2024-04-03T04:24:52.539355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>telugu_instruction</th>\n",
       "      <th>output</th>\n",
       "      <th>telugu_output</th>\n",
       "      <th>instruction_len</th>\n",
       "      <th>output_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>give three tips for staying healthy</td>\n",
       "      <td>ఉండటానికి మూడు చిట్కాలు ఇవ్వండి</td>\n",
       "      <td>eat a balanced and nutritious diet: make sure...</td>\n",
       "      <td>సమతుల్య మరియు పోషకమైన ఆహారం తినండి: మీ భోజనంల...</td>\n",
       "      <td>6</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what are the three primary colors?</td>\n",
       "      <td>ప్రాధమిక రంగులు ఏమిటి?</td>\n",
       "      <td>the three primary colors are red blue and yell...</td>\n",
       "      <td>ప్రాధమిక రంగులు ఎరుపు నీలం మరియు పసుపు. ఈ రంగ...</td>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>describe the structure of an atom</td>\n",
       "      <td>నిర్మాణాన్ని వివరించండి</td>\n",
       "      <td>an atom is the basic building block of all mat...</td>\n",
       "      <td>అనేది అన్ని పదార్ధాల యొక్క ప్రాథమిక బిల్డింగ్...</td>\n",
       "      <td>6</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how can we reduce air pollution?</td>\n",
       "      <td>కాలుష్యాన్ని ఎలా తగ్గించవచ్చు?</td>\n",
       "      <td>there are several ways to reduce air pollution...</td>\n",
       "      <td>కాలుష్యాన్ని తగ్గించడానికి అనేక మార్గాలు ఉన్న...</td>\n",
       "      <td>6</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pretend you are a project manager of a constru...</td>\n",
       "      <td>ఒక కన్ స్ట్రక్షన్ కంపెనీలో ప్రాజెక్ట్ మేనేజర్...</td>\n",
       "      <td>i had to make a difficult decision when i was ...</td>\n",
       "      <td>కన్ స్ట్రక్షన్ కంపెనీలో ప్రాజెక్ట్ మేనేజర్ గా...</td>\n",
       "      <td>21</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0                give three tips for staying healthy   \n",
       "1                 what are the three primary colors?   \n",
       "2                  describe the structure of an atom   \n",
       "3                   how can we reduce air pollution?   \n",
       "4  pretend you are a project manager of a constru...   \n",
       "\n",
       "                                  telugu_instruction  \\\n",
       "0                    ఉండటానికి మూడు చిట్కాలు ఇవ్వండి   \n",
       "1                             ప్రాధమిక రంగులు ఏమిటి?   \n",
       "2                            నిర్మాణాన్ని వివరించండి   \n",
       "3                     కాలుష్యాన్ని ఎలా తగ్గించవచ్చు?   \n",
       "4   ఒక కన్ స్ట్రక్షన్ కంపెనీలో ప్రాజెక్ట్ మేనేజర్...   \n",
       "\n",
       "                                              output  \\\n",
       "0   eat a balanced and nutritious diet: make sure...   \n",
       "1  the three primary colors are red blue and yell...   \n",
       "2  an atom is the basic building block of all mat...   \n",
       "3  there are several ways to reduce air pollution...   \n",
       "4  i had to make a difficult decision when i was ...   \n",
       "\n",
       "                                       telugu_output  instruction_len  \\\n",
       "0   సమతుల్య మరియు పోషకమైన ఆహారం తినండి: మీ భోజనంల...                6   \n",
       "1   ప్రాధమిక రంగులు ఎరుపు నీలం మరియు పసుపు. ఈ రంగ...                6   \n",
       "2   అనేది అన్ని పదార్ధాల యొక్క ప్రాథమిక బిల్డింగ్...                6   \n",
       "3   కాలుష్యాన్ని తగ్గించడానికి అనేక మార్గాలు ఉన్న...                6   \n",
       "4   కన్ స్ట్రక్షన్ కంపెనీలో ప్రాజెక్ట్ మేనేజర్ గా...               21   \n",
       "\n",
       "   output_len  \n",
       "0         121  \n",
       "1          53  \n",
       "2         209  \n",
       "3         216  \n",
       "4         133  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def preprocess_text(text, is_telugu=False):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove end-of-line periods and specific telugu punctuation\n",
    "    text = re.sub(\"\\.$\", '', text)  # English and Telugu common\n",
    "\n",
    "    if is_telugu:\n",
    "        text = re.sub(\"。$\", '', text)  # Telugu-specific\n",
    "    \n",
    "    # Handle punctuation (add spaces or replace based on the case)\n",
    "    text = re.sub(r\"([!#$%&\\()*+,-./:;<=>?@[\\\\]^_`{|}~])\", r\" \\1 \", text)\n",
    "    text = re.sub(r\"['\\\"]\", '', text)  # Remove quotes directly\n",
    "    text = text.replace(\",\", '')  # Handle commas specifically\n",
    "    text = text.replace(\"comma\", '') # Removes comma \n",
    "    # Remove digits\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Normalize spacing (e.g., after removing or altering punctuation)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Remove special char at the start of the string\n",
    "    pattern = r'^[^a-zA-Z0-9\\s]+'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "df['instruction'] = df['instruction'].apply(lambda x: preprocess_text(x))\n",
    "df['telugu_instruction'] = df['telugu_instruction'].apply(lambda x: preprocess_text(x, is_telugu=True))\n",
    "\n",
    "df['output'] = df['output'].apply(lambda x: preprocess_text(x))\n",
    "df['telugu_output'] = df['telugu_output'].apply(lambda x: preprocess_text(x, is_telugu=True))\n",
    "# Review a sample\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selecting first 2 sentences from the large corpus in each row**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:26:12.376997Z",
     "iopub.status.busy": "2024-04-03T04:26:12.376613Z",
     "iopub.status.idle": "2024-04-03T04:26:12.803381Z",
     "shell.execute_reply": "2024-04-03T04:26:12.802182Z",
     "shell.execute_reply.started": "2024-04-03T04:26:12.376968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>telugu_output</th>\n",
       "      <th>output_tlen</th>\n",
       "      <th>tel_output_tlen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eat a balanced and nutritious diet: make sure...</td>\n",
       "      <td>సమతుల్య మరియు పోషకమైన ఆహారం తినండి: మీ భోజనంల...</td>\n",
       "      <td>47</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the three primary colors are red blue and yell...</td>\n",
       "      <td>ప్రాధమిక రంగులు ఎరుపు నీలం మరియు పసుపు. ఈ రంగ...</td>\n",
       "      <td>36</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>an atom is the basic building block of all mat...</td>\n",
       "      <td>అనేది అన్ని పదార్ధాల యొక్క ప్రాథమిక బిల్డింగ్...</td>\n",
       "      <td>43</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there are several ways to reduce air pollution...</td>\n",
       "      <td>కాలుష్యాన్ని తగ్గించడానికి అనేక మార్గాలు ఉన్న...</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i had to make a difficult decision when i was ...</td>\n",
       "      <td>కన్ స్ట్రక్షన్ కంపెనీలో ప్రాజెక్ట్ మేనేజర్ గా...</td>\n",
       "      <td>42</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the commodore was a highly successful -bit hom...</td>\n",
       "      <td>అనేది లో కమోడోర్ బిజినెస్ మెషిన్ (సిబిఎం) తయా...</td>\n",
       "      <td>49</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the fraction / is equivalent to / because both...</td>\n",
       "      <td>/ / కు సమానం ఎందుకంటే రెండు భాగాలు ఒకే విలువన...</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>here are ten items a person might need for a c...</td>\n",
       "      <td>ట్రిప్ కోసం ఒక వ్యక్తికి అవసరమైన పది అంశాలు ఇ...</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the great depression was a period of economic ...</td>\n",
       "      <td>మాంద్యం అనేది - వరకు కొనసాగిన ఆర్థిక క్షీణత క...</td>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the motherboard also known as the mainboard or...</td>\n",
       "      <td>బోర్డ్ మెయిన్ బోర్డ్ లేదా సిస్టమ్ బోర్డ్ అని ...</td>\n",
       "      <td>45</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              output  \\\n",
       "0   eat a balanced and nutritious diet: make sure...   \n",
       "1  the three primary colors are red blue and yell...   \n",
       "2  an atom is the basic building block of all mat...   \n",
       "3  there are several ways to reduce air pollution...   \n",
       "4  i had to make a difficult decision when i was ...   \n",
       "5  the commodore was a highly successful -bit hom...   \n",
       "6  the fraction / is equivalent to / because both...   \n",
       "7  here are ten items a person might need for a c...   \n",
       "8  the great depression was a period of economic ...   \n",
       "9  the motherboard also known as the mainboard or...   \n",
       "\n",
       "                                       telugu_output  output_tlen  \\\n",
       "0   సమతుల్య మరియు పోషకమైన ఆహారం తినండి: మీ భోజనంల...           47   \n",
       "1   ప్రాధమిక రంగులు ఎరుపు నీలం మరియు పసుపు. ఈ రంగ...           36   \n",
       "2   అనేది అన్ని పదార్ధాల యొక్క ప్రాథమిక బిల్డింగ్...           43   \n",
       "3   కాలుష్యాన్ని తగ్గించడానికి అనేక మార్గాలు ఉన్న...           26   \n",
       "4   కన్ స్ట్రక్షన్ కంపెనీలో ప్రాజెక్ట్ మేనేజర్ గా...           42   \n",
       "5   అనేది లో కమోడోర్ బిజినెస్ మెషిన్ (సిబిఎం) తయా...           49   \n",
       "6   / / కు సమానం ఎందుకంటే రెండు భాగాలు ఒకే విలువన...           31   \n",
       "7   ట్రిప్ కోసం ఒక వ్యక్తికి అవసరమైన పది అంశాలు ఇ...           23   \n",
       "8   మాంద్యం అనేది - వరకు కొనసాగిన ఆర్థిక క్షీణత క...           39   \n",
       "9   బోర్డ్ మెయిన్ బోర్డ్ లేదా సిస్టమ్ బోర్డ్ అని ...           45   \n",
       "\n",
       "   tel_output_tlen  \n",
       "0               34  \n",
       "1               28  \n",
       "2               26  \n",
       "3               20  \n",
       "4               29  \n",
       "5               41  \n",
       "6               23  \n",
       "7               18  \n",
       "8               30  \n",
       "9               37  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"output\", \"telugu_output\"]\n",
    "df_1 = df[cols].copy()\n",
    "\n",
    "# Select first 2 sentence\n",
    "df_1['output'] = df_1['output'].apply(lambda x: x.split(\".\")[:2])\n",
    "df_1['telugu_output'] = df_1['telugu_output'].apply(lambda x: x.split(\".\")[:2])\n",
    "\n",
    "# Merge the sentences\n",
    "df_1['output'] = df_1['output'].apply(lambda x: '.'.join(map(str, x)))\n",
    "df_1['telugu_output'] = df_1['telugu_output'].apply(lambda x: '.'.join(map(str, x)))\n",
    "\n",
    "# check the token len\n",
    "df_1['output_tlen'] = df_1['output'].apply(lambda x: len(x.split()))\n",
    "df_1['tel_output_tlen'] = df_1['telugu_output'].apply(lambda x: len(x.split()))\n",
    "\n",
    "df_1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:26:23.141260Z",
     "iopub.status.busy": "2024-04-03T04:26:23.140934Z",
     "iopub.status.idle": "2024-04-03T04:26:23.147653Z",
     "shell.execute_reply": "2024-04-03T04:26:23.146726Z",
     "shell.execute_reply.started": "2024-04-03T04:26:23.141235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' eat a balanced and nutritious diet: make sure your meals are inclusive of a variety of fruits and vegetables lean protein whole grains and healthy fats. this helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases',\n",
       " ' సమతుల్య మరియు పోషకమైన ఆహారం తినండి: మీ భోజనంలో వివిధ రకాల పండ్లు మరియు కూరగాయలు సన్నని ప్రోటీన్ తృణధాన్యాలు మరియు ఆరోగ్యకరమైన కొవ్వులు ఉన్నాయని నిర్ధారించుకోండి. ఇది మీ శరీరానికి ఉత్తమంగా పనిచేయడానికి అవసరమైన పోషకాలను అందించడంలో సహాయపడుతుంది మరియు దీర్ఘకాలిక వ్యాధులను నివారించడంలో సహాయపడుతుంది')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.output.values[0], df_1.telugu_output.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation for training\n",
    "- Sampling\n",
    "- Tokenizing\n",
    "- Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:27:07.331737Z",
     "iopub.status.busy": "2024-04-03T04:27:07.331314Z",
     "iopub.status.idle": "2024-04-03T04:27:07.353527Z",
     "shell.execute_reply": "2024-04-03T04:27:07.352643Z",
     "shell.execute_reply.started": "2024-04-03T04:27:07.331708Z"
    }
   },
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "\n",
    "df_1 = df_1.dropna().reset_index(drop=True)\n",
    "df_sample = df_1.sample(n_samples)\n",
    "\n",
    "\n",
    "# Input Sentences - English\n",
    "inp_sentences_untok = df_sample.output.tolist()\n",
    "\n",
    "# Target Sentences - Telugu\n",
    "target_sentences_untok =  df_sample.telugu_output.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:27:17.609485Z",
     "iopub.status.busy": "2024-04-03T04:27:17.608849Z",
     "iopub.status.idle": "2024-04-03T04:27:17.633943Z",
     "shell.execute_reply": "2024-04-03T04:27:17.632988Z",
     "shell.execute_reply.started": "2024-04-03T04:27:17.609456Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(target_sentences_untok)):\n",
    "    target_sentences_untok[i] = \"<start> \" + str(target_sentences_untok[i]) + \" <end>\"\n",
    "    inp_sentences_untok[i] = \"<start> \" + str(inp_sentences_untok[i]) + \" <end>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:27:18.715511Z",
     "iopub.status.busy": "2024-04-03T04:27:18.714685Z",
     "iopub.status.idle": "2024-04-03T04:27:20.174168Z",
     "shell.execute_reply": "2024-04-03T04:27:20.173245Z",
     "shell.execute_reply.started": "2024-04-03T04:27:18.715482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words in the English vocabulary: 32925\n"
     ]
    }
   ],
   "source": [
    "num_words = 15000\n",
    "tokenizer_tar = Tokenizer(num_words=num_words, filters='!#$%&()*+,-/:;<=>@«»\"\"[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer_tar.fit_on_texts(target_sentences_untok)\n",
    "target_sentences = tokenizer_tar.texts_to_sequences(target_sentences_untok)\n",
    "\n",
    "word_index = tokenizer_tar.word_index\n",
    "print(f\"The number of words in the English vocabulary: {len(word_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:27:21.330660Z",
     "iopub.status.busy": "2024-04-03T04:27:21.329776Z",
     "iopub.status.idle": "2024-04-03T04:27:22.063428Z",
     "shell.execute_reply": "2024-04-03T04:27:22.062455Z",
     "shell.execute_reply.started": "2024-04-03T04:27:21.330628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words in the Telugu vocabulary: 20393\n"
     ]
    }
   ],
   "source": [
    "tokenizer_inp = Tokenizer(num_words=num_words, filters='!#$%&()*+,-/:;<=>@«»\"\"[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer_inp.fit_on_texts(inp_sentences_untok)\n",
    "inp_sentences = tokenizer_inp.texts_to_sequences(inp_sentences_untok)\n",
    "\n",
    "word_index_inp = tokenizer_inp.word_index\n",
    "print(f\"The number of words in the Telugu vocabulary: {len(word_index_inp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:27:22.538050Z",
     "iopub.status.busy": "2024-04-03T04:27:22.537709Z",
     "iopub.status.idle": "2024-04-03T04:27:22.546553Z",
     "shell.execute_reply": "2024-04-03T04:27:22.545519Z",
     "shell.execute_reply.started": "2024-04-03T04:27:22.538026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max token length in English: 265, in Telugu: 325 and selected max-len for padding is: 325\n"
     ]
    }
   ],
   "source": [
    "# Find the maximum length of tokenized sentences in english and telugu tokenized sentences.\n",
    "max_len_en = max(len(lst) for lst in target_sentences)\n",
    "max_len_tel = max(len(lst) for lst in inp_sentences)\n",
    "\n",
    "MAX_LEN = max(max_len_en, max_len_tel)\n",
    "print(f\"Max token length in English: {max_len_en}, in Telugu: {max_len_tel} and selected max-len for padding is: {MAX_LEN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:27:23.211828Z",
     "iopub.status.busy": "2024-04-03T04:27:23.211010Z",
     "iopub.status.idle": "2024-04-03T04:27:23.348157Z",
     "shell.execute_reply": "2024-04-03T04:27:23.346948Z",
     "shell.execute_reply.started": "2024-04-03T04:27:23.211775Z"
    }
   },
   "outputs": [],
   "source": [
    "target_sentences = pad_sequences(target_sentences, maxlen = MAX_LEN, padding='post', truncating='post')\n",
    "inp_sentences = pad_sequences(inp_sentences, maxlen=MAX_LEN, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "#### Helper Functions for transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:27:24.020689Z",
     "iopub.status.busy": "2024-04-03T04:27:24.019971Z",
     "iopub.status.idle": "2024-04-03T04:27:24.028411Z",
     "shell.execute_reply": "2024-04-03T04:27:24.027457Z",
     "shell.execute_reply.started": "2024-04-03T04:27:24.020660Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, embedding_dim):\n",
    "    \"\"\"\n",
    "    Function to compute the angles for positional encoding.\n",
    "    \n",
    "    Returns the angle computed\n",
    "    \"\"\"\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(embedding_dim))\n",
    "    return pos * angle_rates\n",
    "\n",
    "\n",
    "def positional_encoding(position, embedding_dim):\n",
    "    \"\"\"\n",
    "    Adds  positional encoding to the Embeddings to be fed to the Transformer model.\n",
    "    \n",
    "    Computes a sin and cos of the angles determined by the get_angles() function\n",
    "    and adds the value computed to an axis of the embeddings.\n",
    "    \"\"\"\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis], \n",
    "                           np.arange(embedding_dim)[np.newaxis, :], embedding_dim)\n",
    "    \n",
    "    # apply sin to even indices in the array. ie 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    \n",
    "    # apply cos to odd indices in the array. ie 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:27:24.606551Z",
     "iopub.status.busy": "2024-04-03T04:27:24.605897Z",
     "iopub.status.idle": "2024-04-03T04:27:24.615216Z",
     "shell.execute_reply": "2024-04-03T04:27:24.614182Z",
     "shell.execute_reply.started": "2024-04-03T04:27:24.606521Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    \"\"\"\n",
    "    Creates a padding mask for a given sequence.\n",
    "    \n",
    "    Args:\n",
    "        seq (tensor): A tensor of shape (batch_size, seq_len) containing the sequence.\n",
    "        \n",
    "    Returns:\n",
    "        A tensor of shape (batch_size, 1, 1, seq_len) containing a mask that is 1 where the sequence is padded, and 0 otherwise.\n",
    "    \"\"\"\n",
    "    # Convert the sequence to a boolean tensor where True indicates a pad token (value 0).\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    \n",
    "    # Add an extra dimension to the mask to add the padding to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    \"\"\"\n",
    "    Creates a look-ahead mask used during training the decoder of a transformer.\n",
    "\n",
    "    Args:\n",
    "        size (int): The size of the mask.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: A lower triangular matrix of shape (size, size) with ones on the diagonal\n",
    "            and zeros below the diagonal.\n",
    "    \"\"\"\n",
    "    # create a matrix with ones on the diagonal and zeros below the diagonal\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def create_masks(inputs, targets):\n",
    "    \"\"\"\n",
    "    Creates masks for the input sequence and target sequence.\n",
    "    \n",
    "    Args:\n",
    "        inputs: Input sequence tensor.\n",
    "        targets: Target sequence tensor.\n",
    "    \n",
    "    Returns:\n",
    "        A tuple of three masks: the encoder padding mask, the combined mask used in the first attention block, \n",
    "        and the decoder padding mask used in the second attention block.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the encoder padding mask.\n",
    "    enc_padding_mask = create_padding_mask(inputs)\n",
    "        \n",
    "    # Create the decoder padding mask.\n",
    "    dec_padding_mask = create_padding_mask(inputs)\n",
    "        \n",
    "    # Create the look ahead mask for the first attention block.\n",
    "    # It is used to pad and mask future tokens in the tokens received by the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(targets)[1])\n",
    "    \n",
    "    # Create the decoder target padding mask.\n",
    "    dec_target_padding_mask = create_padding_mask(targets)\n",
    "    \n",
    "    # Combine the look ahead mask and decoder target padding mask for the first attention block.\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "        \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Mechanism - Multihead Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:27:25.387185Z",
     "iopub.status.busy": "2024-04-03T04:27:25.386386Z",
     "iopub.status.idle": "2024-04-03T04:27:25.394311Z",
     "shell.execute_reply": "2024-04-03T04:27:25.393369Z",
     "shell.execute_reply.started": "2024-04-03T04:27:25.387156Z"
    }
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"\n",
    "    Computes the scaled dot product attention weight for the query (q), key (k), and value (v) vectors. \n",
    "    The attention weight is a measure of how much focus should be given to each element in the sequence of values (v) \n",
    "    based on the corresponding element in the sequence of queries (q) and keys (k).\n",
    "    \n",
    "    Args:\n",
    "    q: query vectors; shape (..., seq_len_q, depth)\n",
    "    k: key vectors; shape  (..., seq_len_k, depth)\n",
    "    v: value vectors; shape  (..., seq_len_v, depth_v)\n",
    "    mask: (optional) mask to be applied to the attention weights\n",
    "    \n",
    "    Returns:\n",
    "    output: The output of the scaled dot product attention computation; shape   (..., seq_len_q, depth_v)\n",
    "    attention_weights: The attention weights\n",
    "    \"\"\"\n",
    "    # Compute dot product of query and key vectors\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "    \n",
    "    # Compute the square root of the depth of the key vectors\n",
    "    dk = tf.cast(tf.shape(k)[-1], dtype=tf.float32)\n",
    "    scaled_dk = tf.math.sqrt(dk)\n",
    "    \n",
    "    # Compute scaled attention logits by dividing dot product by scaled dk\n",
    "    scaled_attention_logits = matmul_qk / scaled_dk\n",
    "    \n",
    "    # Apply mask to the attention logits (if mask is not None)\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "        \n",
    "    # Apply softmax to the scaled attention logits to get the attention weights\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "    \n",
    "    # Compute the weighted sum of the value vectors using the attention weights\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    \n",
    "    return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:27:25.751414Z",
     "iopub.status.busy": "2024-04-03T04:27:25.750619Z",
     "iopub.status.idle": "2024-04-03T04:27:25.765451Z",
     "shell.execute_reply": "2024-04-03T04:27:25.764585Z",
     "shell.execute_reply.started": "2024-04-03T04:27:25.751384Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    MultiHeadAttention Layer that implements the attention mechanism for the Transformer.\n",
    "    It splits the input into multiple heads, computes scaled dot-product attention for each head\n",
    "    and then concatenates the output of the heads and passes it through a dense layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, key_dim, num_heads, dropout_rate=0.0):\n",
    "        \"\"\"\n",
    "        Initializes the MultiHeadAttention layer.\n",
    "    \n",
    "        Args:\n",
    "            key_dim (int): The dimensionality of the key space.\n",
    "            num_heads (int): The number of attention heads.\n",
    "            dropout (float): The dropout rate to apply after the dense layer.\n",
    "        \"\"\"\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.key_dim = key_dim\n",
    "        #  ensure  that the dimension of the embedding can be evenly split across attention heads\n",
    "        assert key_dim % num_heads == 0 \n",
    "        self.depth = self.key_dim // self.num_heads\n",
    "        \n",
    "        # dense layers to project the input into queries, keys and values\n",
    "        self.wq = Dense(key_dim)\n",
    "        self.wk = Dense(key_dim)\n",
    "        self.wv = Dense(key_dim)\n",
    "    \n",
    "        # dropout layer\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "    \n",
    "        # dense layer to project the output of the attention heads\n",
    "        self.dense = Dense(key_dim)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"\n",
    "        Splits the last dimension of the tensor into (num_heads, depth).\n",
    "        Transposes the result such that the shape is (batch_size, num_heads, seq_len, depth).\n",
    "    \n",
    "        Args:\n",
    "            x (tensor): The tensor to be split.\n",
    "            batch_size (int): The size of the batch.\n",
    "    \n",
    "        Returns:\n",
    "            tensor: The tensor with the last dimension split into (num_heads, depth) and transposed.\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        \n",
    "    def call(self, v, k, q, mask=None):\n",
    "        \"\"\"\n",
    "        Applies the multi-head attention mechanism to the inputs.\n",
    "    \n",
    "        Args:\n",
    "            v (tensor): The value tensor of shape (batch_size, seq_len_v, key_dim).\n",
    "            k (tensor): The key tensor of shape (batch_size, seq_len_k, key_dim).\n",
    "            q (tensor): The query tensor of shape (batch_size, seq_len_q, key_dim).\n",
    "            mask (tensor, optional): The mask tensor of shape (batch_size, seq_len_q, seq_len_k).\n",
    "                                     Defaults to None.\n",
    "    \n",
    "        Returns:\n",
    "            tensor: The output tensor of shape (batch_size, seq_len_q, key_dim).\n",
    "            tensor: The attention weights tensor of shape (batch_size, num_heads, seq_len_q, seq_len_k).\n",
    "        \"\"\"\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        # Dense on the q, k, v vectors\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "        \n",
    "        # split the heads\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        \n",
    "        # split the queries, keys and values into multiple heads\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        # reshape and add Dense layer\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.key_dim))\n",
    "        output = self.dense(concat_attention)\n",
    "        output = self.dropout(output)\n",
    "        \n",
    "        return output, attention_weights\n",
    "    \n",
    "\n",
    "### Fully Connected NeuralNetwork\n",
    "    \n",
    "def FeedForward(embedding_dim, fully_connected_dim):\n",
    "    \"\"\"Create a fully connected feedforward neural network.\n",
    "    \n",
    "    Args:\n",
    "        embedding_dim (int): Dimensionality of the embedding output from the transformer layer.\n",
    "        fully_connected_dim (int): Number of neurons in the fully connected layers.\n",
    "    \n",
    "    Returns:\n",
    "        tf.keras.Sequential: A fully connected feedforward neural network with the specified architecture.\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(fully_connected_dim, activation='relu'),\n",
    "        tf.keras.layers.Dense(embedding_dim)\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:27:26.118872Z",
     "iopub.status.busy": "2024-04-03T04:27:26.118533Z",
     "iopub.status.idle": "2024-04-03T04:27:26.134168Z",
     "shell.execute_reply": "2024-04-03T04:27:26.133255Z",
     "shell.execute_reply.started": "2024-04-03T04:27:26.118847Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, embedding_dim, num_heads, fully_connected_dim, dropout_rate=0.1):\n",
    "        \"\"\"Initializes the encoder layer\n",
    "        \n",
    "        Args: \n",
    "            embedding_dim: The dimensionality of the input and output of this layer\n",
    "            num_heads: The number of attention heads to use in the multi-head attention layer\n",
    "            fully_connected_dim: The dimensionality of the hidden layer in the feedforward network\n",
    "            dropout_rate: The rate of dropout to apply to the output of this layer during training\n",
    "            \n",
    "        Returns:\n",
    "            A new instance of the EncoderLayer class\n",
    "        \"\"\"\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        # Multi-head self-attention mechanism\n",
    "        self.mha = MultiHeadAttention(embedding_dim, num_heads, dropout_rate)\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        \n",
    "        # Feedforward network\n",
    "        self.ffn = FeedForward(embedding_dim, fully_connected_dim)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        \"\"\"Applies the encoder layer to the input tensor\n",
    "        \n",
    "        Args:\n",
    "            x: The input tensor to the encoder layer\n",
    "            training: A boolean indicating whether the model is in training mode\n",
    "            mask: A tensor representing the mask to apply to the attention mechanism\n",
    "            \n",
    "        Returns:\n",
    "            The output of the encoder layer after applying the multi-head attention and feedforward network\n",
    "        \"\"\"\n",
    "        \n",
    "        # Apply multi-head self-attention mechanism to input tensor\n",
    "        attn_output, _ = self.mha(x, x, x, mask)\n",
    "        \n",
    "        # Apply first layer normalization and add residual connection\n",
    "        out1 = self.layernorm1(attn_output + x)\n",
    "        \n",
    "        # Apply feedforward network to output of first layer normalization\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout(ffn_output, training=training)\n",
    "        \n",
    "        # Apply second layer normalization and add residual connection\n",
    "        out2 = self.layernorm2(ffn_output + out1)\n",
    "        \n",
    "        return out2\n",
    "    \n",
    "\n",
    "#### Encoder \n",
    "    \n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, input_vocab_size, maximum_position_encoding, dropout_rate=0.1):\n",
    "        \"\"\"\n",
    "        Initializes the Encoder layer of the Transformer model.\n",
    "        \n",
    "        Args:\n",
    "            num_layers (int): Number of EncoderLayers to stack.\n",
    "            embedding_dim (int): Dimensionality of the token embedding space.\n",
    "            num_heads (int): Number of attention heads to use in MultiHeadAttention layers.\n",
    "            fully_connected_dim (int): Dimensionality of the fully connected layer in the EncoderLayer.\n",
    "            input_vocab_size (int): Size of the input vocabulary.\n",
    "            maximum_position_encoding (int): Maximum length of input sequences for positional encoding.\n",
    "            dropout_rate (float): Probability of dropping out units during training.\n",
    "\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = Embedding(input_vocab_size, embedding_dim)\n",
    "        \n",
    "        # Positional encoding\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, embedding_dim)\n",
    "        \n",
    "        # Encoder layers\n",
    "        self.enc_layers = [EncoderLayer(embedding_dim, num_heads, fully_connected_dim, dropout_rate) for _ in range(num_layers)]\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        \n",
    "    def call(self, inputs, training, mask):\n",
    "        \"\"\"\n",
    "        Call function for the Encoder layer.\n",
    "        \n",
    "        Args:\n",
    "            inputs: tensor of shape (batch_size, sequence_length) representing input sequences\n",
    "            training: boolean indicating if the model is in training mode\n",
    "            mask: tensor of shape (batch_size, sequence_length) representing the mask to apply to the input sequence\n",
    "\n",
    "        Returns:\n",
    "            A tensor of shape (batch_size, sequence_length, embedding_dim) representing the encoded sequence\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the sequence length\n",
    "        seq_len = tf.shape(inputs)[1]\n",
    "\n",
    "        # Embed the input sequence\n",
    "        inputs = self.embedding(inputs)\n",
    "\n",
    "        # Scale the embeddings by sqrt(embedding_dim)\n",
    "        inputs *= tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
    "\n",
    "        # Add positional encodings to the input sequence\n",
    "        inputs += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        # Apply dropout to the input sequence\n",
    "        inputs = self.dropout(inputs, training=training)\n",
    "\n",
    "        # Pass the input sequence through the encoder layers\n",
    "        for i in range(self.num_layers):\n",
    "            inputs = self.enc_layers[i](inputs, training, mask)\n",
    "\n",
    "        # Return the encoded sequence\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:27:26.480968Z",
     "iopub.status.busy": "2024-04-03T04:27:26.480622Z",
     "iopub.status.idle": "2024-04-03T04:27:26.498697Z",
     "shell.execute_reply": "2024-04-03T04:27:26.497840Z",
     "shell.execute_reply.started": "2024-04-03T04:27:26.480943Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, embedding_dim, num_heads, fully_connected_dim, dropout_rate=0.1):\n",
    "        \"\"\"\n",
    "        Initializes a single decoder layer of the transformer model.\n",
    "        \n",
    "        Args:\n",
    "        embedding_dim: The dimension of the embedding space.\n",
    "        num_heads: The number of attention heads to use.\n",
    "        fully_connected_dim: The dimension of the feedforward network.\n",
    "        rate: The dropout rate for regularization.\n",
    "        \"\"\"\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        # Instantiate two instances of MultiHeadAttention.\n",
    "        self.mha1 = MultiHeadAttention(embedding_dim, num_heads, dropout_rate)\n",
    "        self.mha2 = MultiHeadAttention(embedding_dim, num_heads, dropout_rate)\n",
    "        \n",
    "        # Instantiate a fully connected feedforward network.\n",
    "        self.ffn = FeedForward(embedding_dim, fully_connected_dim)\n",
    "        \n",
    "        # Instantiate three layer normalization layers with epsilon=1e-6.\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        # Instantiate a dropout layer for regularization.\n",
    "        self.dropout3 = Dropout(dropout_rate)\n",
    "        \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        \"\"\"\n",
    "        Forward pass through the decoder layer.\n",
    "        \n",
    "        Args:\n",
    "        x: The input to the decoder layer, a query vector.\n",
    "        enc_output: The output from the top layer of the encoder, a set of attention vectors k and v.\n",
    "        training: Whether to apply dropout regularization.\n",
    "        look_ahead_mask: The mask to apply to the input sequence so that it can't look ahead to future positions.\n",
    "        padding_mask: The mask to apply to the input sequence to ignore padding tokens.\n",
    "        \n",
    "        Returns:\n",
    "        The output from the decoder layer, a tensor with the same shape as the input.\n",
    "        The attention weights from the first multi-head attention layer.\n",
    "        The attention weights from the second multi-head attention layer.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Apply the first multi-head attention layer to the query vector x.\n",
    "        # We pass x as all three inputs to the layer because this is a self-attention layer.\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
    "        \n",
    "        # Add the original input to the output of the attention layer and apply layer normalization.\n",
    "        out1 = self.layernorm1(attn1 + x) \n",
    "        \n",
    "        # Apply the second multi-head attention layer to the output from the first layer and the encoder output.\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
    "        \n",
    "        # Add the output from the first layer to the output of the second layer and apply layer normalization.\n",
    "        out2 = self.layernorm2(attn2 + out1)\n",
    "        \n",
    "        # Apply the feedforward network to the output of the second layer and apply dropout regularization.\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        \n",
    "        # Add the output from the second layer to the output of the feedforward network and apply layer normalization.\n",
    "        out3 = self.layernorm3(ffn_output + out2)\n",
    "        \n",
    "        return out3, attn_weights_block1, attn_weights_block2\n",
    "\n",
    "\n",
    "### Decoder\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, target_vocab_size, maximum_position_encoding, dropout_rate=0.1):\n",
    "        \"\"\"\n",
    "        Initializes the Decoder object.\n",
    "        \n",
    "        Args:\n",
    "            num_layers (int): The number of Decoder layers.\n",
    "            embedding_dim (int): The size of the embedding dimension.\n",
    "            num_heads (int): The number of heads in the MultiHeadAttention layer.\n",
    "            fully_connected_dim (int): The number of units in the feedforward network.\n",
    "            target_vocab_size (int): The number of words in the target vocabulary.\n",
    "            maximum_position_encoding (int): The maximum length of a sequence.\n",
    "            dropout_rate (float): The rate at which to apply dropout.\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # create layers\n",
    "        self.embedding = Embedding(target_vocab_size, embedding_dim)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, embedding_dim)\n",
    "        self.dec_layers = [DecoderLayer(embedding_dim, num_heads, fully_connected_dim, dropout_rate=0.1) for _ in range(num_layers)]\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        \"\"\"\n",
    "        Executes the Decoder.\n",
    "\n",
    "        Args:\n",
    "            x (tf.Tensor): The input to the Decoder.\n",
    "            enc_output (tf.Tensor): The output from the Encoder.\n",
    "            training (bool): Whether the Decoder is in training mode.\n",
    "            look_ahead_mask (tf.Tensor): The mask for self-attention in the MultiHeadAttention layer.\n",
    "            padding_mask (tf.Tensor): The mask for padding in the MultiHeadAttention layer.\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The output from the Decoder.\n",
    "            dict: A dictionary of attention weights.\n",
    "        \"\"\"\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        # add embedding and positional encoding\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        # apply each layer of the decoder\n",
    "        for i in range(self.num_layers):\n",
    "            # pass through decoder layer i\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
    "\n",
    "            # record attention weights for block1 and block2\n",
    "            attention_weights[f\"decoder_layer{i + 1}_block1\"] = block1\n",
    "            attention_weights[f\"decoder_layer{i + 1}_block2\"] = block2\n",
    "\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:27:26.841607Z",
     "iopub.status.busy": "2024-04-03T04:27:26.841231Z",
     "iopub.status.idle": "2024-04-03T04:27:26.851588Z",
     "shell.execute_reply": "2024-04-03T04:27:26.850706Z",
     "shell.execute_reply.started": "2024-04-03T04:27:26.841578Z"
    }
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    A Transformer model that takes in an input and target sequence and outputs a final prediction.\n",
    "\n",
    "    Args:\n",
    "        num_layers (int): Number of layers in the Encoder and Decoder.\n",
    "        embedding_dim (int): Dimensionality of the embedding layer.\n",
    "        num_heads (int): Number of attention heads used in the Transformer.\n",
    "        fully_connected_dim (int): Dimensionality of the fully connected layer in the Encoder and Decoder.\n",
    "        input_vocab_size (int): Size of the input vocabulary.\n",
    "        target_vocab_size (int): Size of the target vocabulary.\n",
    "        max_positional_encoding_input (int): Maximum length of the input sequence.\n",
    "        max_positional_encoding_target (int): Maximum length of the target sequence.\n",
    "        dropout_rate (float, optional): Dropout rate used in the Encoder and Decoder layers. Defaults to 0.1.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, input_vocab_size, target_vocab_size, max_positional_encoding_input, max_positional_encoding_target, dropout_rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        # Initialize the Encoder and Decoder layers\n",
    "        self.encoder = Encoder(num_layers, embedding_dim, num_heads, fully_connected_dim, input_vocab_size, max_positional_encoding_input, dropout_rate)\n",
    "        self.decoder = Decoder(num_layers, embedding_dim, num_heads, fully_connected_dim, input_vocab_size, max_positional_encoding_target, dropout_rate)\n",
    "        \n",
    "        # Add a final dense layer to make the final prediction\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size, activation='softmax')\n",
    "        \n",
    "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "        \"\"\"\n",
    "        Perform a forward pass through the Transformer model.\n",
    "\n",
    "        Args:\n",
    "            inp (tf.Tensor): Input sequence tensor with shape (batch_size, input_seq_len).\n",
    "            tar (tf.Tensor): Target sequence tensor with shape (batch_size, target_seq_len).\n",
    "            training (bool): Whether the model is being trained or not.\n",
    "            enc_padding_mask (tf.Tensor): Padding mask for the Encoder with shape (batch_size, 1, 1, input_seq_len).\n",
    "            look_ahead_mask (tf.Tensor): Mask to prevent the Decoder from looking ahead in the target sequence with shape (batch_size, 1, target_seq_len, target_seq_len).\n",
    "            dec_padding_mask (tf.Tensor): Padding mask for the Decoder with shape (batch_size, 1, 1, target_seq_len).\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing the final output of the model and the attention weights of the Decoder.\n",
    "        \"\"\"\n",
    "        # Pass the input sequence through the Encoder\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
    "        \n",
    "        # Pass the target sequence and the output of the Encoder through the Decoder\n",
    "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "        \n",
    "        # Pass the output of the Decoder through the final dense layer to get the final prediction\n",
    "        final_output = self.final_layer(dec_output)\n",
    "        \n",
    "        return final_output, attention_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Hyperparameters <a name=\"5-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:27:43.516136Z",
     "iopub.status.busy": "2024-04-03T04:27:43.515477Z",
     "iopub.status.idle": "2024-04-03T04:27:43.521938Z",
     "shell.execute_reply": "2024-04-03T04:27:43.521007Z",
     "shell.execute_reply.started": "2024-04-03T04:27:43.516100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set hyperparameters for the Transformer model\n",
    "embedding_dim = 256          # dimensionality of the embeddings used for tokens in the input and target sequences\n",
    "fully_connected_dim = 512    # dimensionality of the hidden layer of the feedforward neural network within the Transformer block\n",
    "num_layers = 4               # number of Transformer blocks in the encoder and decoder stacks\n",
    "num_heads = 8                # number of heads in the multi-head attention mechanism\n",
    "dropout_rate = 0.1           # dropout rate for regularization\n",
    "\n",
    "# Set vocabulary sizes for input and target sequences\n",
    "input_vocab_size = len(tokenizer_inp.word_index) + 1    # add 1 for the start and end tokens\n",
    "target_vocab_size = len(tokenizer_tar.word_index) + 1   # add 1 for the start and end tokens\n",
    "\n",
    "# Set maximum positional encoding values for input and target sequences\n",
    "max_positional_encoding_input = input_vocab_size    # maximum positional encoding value for input sequence\n",
    "max_positional_encoding_target = target_vocab_size  # maximum positional encoding value for target sequence\n",
    "\n",
    "# Set the number of epochs and batch size for training\n",
    "EPOCHS = 50\n",
    "batch_size = 32\n",
    "\n",
    "MAX_LEN = MAX_LEN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:28:00.670271Z",
     "iopub.status.busy": "2024-04-03T04:28:00.669940Z",
     "iopub.status.idle": "2024-04-03T04:28:01.285431Z",
     "shell.execute_reply": "2024-04-03T04:28:01.284498Z",
     "shell.execute_reply.started": "2024-04-03T04:28:00.670247Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, embedding_dim, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.embedding_dim = tf.cast(embedding_dim, dtype=tf.float32)\n",
    "        self.warmup_steps = tf.cast(warmup_steps, dtype=tf.float32)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, dtype=tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        return tf.math.rsqrt(self.embedding_dim) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "# Create an instance of the custom learning rate schedule\n",
    "learning_rate = CustomSchedule(embedding_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function and Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:28:03.214429Z",
     "iopub.status.busy": "2024-04-03T04:28:03.213771Z",
     "iopub.status.idle": "2024-04-03T04:28:04.658893Z",
     "shell.execute_reply": "2024-04-03T04:28:04.658069Z",
     "shell.execute_reply.started": "2024-04-03T04:28:03.214398Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2 = 0.98, epsilon = 1e-9)\n",
    "\n",
    "# Define the loss object\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "\n",
    "def loss_function(true_values, predictions):\n",
    "    # Create a mask to exclude the padding tokens\n",
    "    mask = tf.math.logical_not(tf.math.equal(true_values, 0))\n",
    "\n",
    "    # Compute the loss value using the loss object\n",
    "    loss_ = loss_object(true_values, predictions)\n",
    "\n",
    "    # Apply the mask to exclude the padding tokens\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    # Calculate the mean loss value\n",
    "    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)\n",
    "\n",
    "def accuracy_function(true_values, predictions):\n",
    "    # Compute the accuracies using the true and predicted target sequences\n",
    "    accuracies = tf.equal(true_values, tf.argmax(predictions, axis=2))\n",
    "\n",
    "    # Create a mask to exclude the padding tokens\n",
    "    mask = tf.math.logical_not(tf.math.equal(true_values, 0))\n",
    "\n",
    "    # Apply the mask to exclude the padding tokens from the accuracies\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "\n",
    "    # Calculate the mean accuracy value\n",
    "    return tf.reduce_sum(accuracies) / tf.reduce_sum(mask)\n",
    "\n",
    "# Define the training metrics\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:28:04.660832Z",
     "iopub.status.busy": "2024-04-03T04:28:04.660521Z",
     "iopub.status.idle": "2024-04-03T04:28:05.282443Z",
     "shell.execute_reply": "2024-04-03T04:28:05.281446Z",
     "shell.execute_reply.started": "2024-04-03T04:28:04.660777Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create an instance of the Transformer model\n",
    "transformer = Transformer(num_layers, embedding_dim, num_heads,\n",
    "                           fully_connected_dim, input_vocab_size, target_vocab_size, \n",
    "                           max_positional_encoding_input, max_positional_encoding_target, dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:28:05.284039Z",
     "iopub.status.busy": "2024-04-03T04:28:05.283686Z",
     "iopub.status.idle": "2024-04-03T04:28:05.293685Z",
     "shell.execute_reply": "2024-04-03T04:28:05.292750Z",
     "shell.execute_reply.started": "2024-04-03T04:28:05.284008Z"
    }
   },
   "outputs": [],
   "source": [
    "# the train function\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(encoder_input, target):\n",
    "    # Slice the target tensor to get the input for the decoder\n",
    "    decoder_input = target[:, :-1]\n",
    "\n",
    "    # Slice the target tensor to get the expected output of the decoder\n",
    "    expected_output = target[:, 1:]\n",
    "\n",
    "    # Create masks for the encoder input, decoder input and the padding\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, decoder_input)\n",
    "\n",
    "    # Perform a forward pass through the model\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(encoder_input, decoder_input, True, enc_padding_mask, combined_mask, dec_padding_mask)\n",
    "\n",
    "        # Calculate the loss between the predicted output and the expected output\n",
    "        loss = loss_function(expected_output, predictions)\n",
    "\n",
    "    # Calculate gradients and update the model parameters\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    # Update the training loss and accuracy metrics\n",
    "    train_loss(loss)\n",
    "    train_accuracy(expected_output, predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:28:05.295896Z",
     "iopub.status.busy": "2024-04-03T04:28:05.295603Z",
     "iopub.status.idle": "2024-04-03T04:28:05.308323Z",
     "shell.execute_reply": "2024-04-03T04:28:05.307485Z",
     "shell.execute_reply.started": "2024-04-03T04:28:05.295873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-04-03-04-28'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the current date and time\n",
    "current_time = datetime.now()\n",
    "\n",
    "# Format the current date and time into a string\n",
    "time_str = current_time.strftime(\"%Y-%m-%d-%H-%M\")\n",
    "time_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizer Saving\n",
    "- Save both Tokenizers - English (Input), Telugu (Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:28:06.047274Z",
     "iopub.status.busy": "2024-04-03T04:28:06.046919Z",
     "iopub.status.idle": "2024-04-03T04:28:06.054161Z",
     "shell.execute_reply": "2024-04-03T04:28:06.053192Z",
     "shell.execute_reply.started": "2024-04-03T04:28:06.047247Z"
    }
   },
   "outputs": [],
   "source": [
    "training_model_name_to_save = f\"{time_str}_{embedding_dim}_{fully_connected_dim}_{num_layers}_{num_heads}_{dropout_rate}_{input_vocab_size}_{target_vocab_size}_{EPOCHS}_{batch_size}_{MAX_LEN}\"\n",
    "\n",
    "# Dictionary to hold multiple tokenizers - English + Telugu\n",
    "tokenizers_dict = {\n",
    "    'english_tokenizer_target': tokenizer_tar,\n",
    "    'telugu_tokenizer_input': tokenizer_inp\n",
    "}\n",
    "\n",
    "# Create the 'artifacts' directory if it doesn't exist\n",
    "if not os.path.exists('transformer_training_artifacts'):\n",
    "    os.makedirs('transformer_training_artifacts/tokenizer')\n",
    "    os.makedirs('transformer_training_artifacts/training_checkpoints')\n",
    "\n",
    "def save_the_tokenizer():\n",
    "    # Save the tokenizer - english & telugu\n",
    "    with open(f'transformer_training_artifacts/tokenizer/tokenizer_{training_model_name_to_save}.pickle', 'wb') as handle:\n",
    "        pickle.dump(tokenizers_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:28:07.438470Z",
     "iopub.status.busy": "2024-04-03T04:28:07.438112Z",
     "iopub.status.idle": "2024-04-03T04:28:07.447268Z",
     "shell.execute_reply": "2024-04-03T04:28:07.446352Z",
     "shell.execute_reply.started": "2024-04-03T04:28:07.438439Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_path = f\"transformer_training_artifacts/training_checkpoints/transformer_{training_model_name_to_save}\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=3)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:28:11.212840Z",
     "iopub.status.busy": "2024-04-03T04:28:11.212482Z",
     "iopub.status.idle": "2024-04-03T06:26:19.432569Z",
     "shell.execute_reply": "2024-04-03T06:26:19.431650Z",
     "shell.execute_reply.started": "2024-04-03T04:28:11.212813Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1712118517.334202     253 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "  2%|▏         | 1/50 [03:02<2:29:13, 182.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 7.2520 Accuracy 0.8438\n",
      "Time taken for 1 epoch: 182.71731042861938 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [05:23<2:06:22, 157.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss 1.1992 Accuracy 0.9188\n",
      "Time taken for 1 epoch: 140.64455676078796 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [07:44<1:57:36, 150.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss 0.6433 Accuracy 0.9234\n",
      "Time taken for 1 epoch: 140.8220772743225 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [10:04<1:52:16, 146.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss 0.6062 Accuracy 0.9251\n",
      "Time taken for 1 epoch: 140.8088574409485 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [12:26<1:48:36, 144.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint for epoch 6 at transformer_training_artifacts/training_checkpoints/transformer_2024-04-03-04-28_256_512_4_8_0.1_20394_32926_50_32_325/ckpt-1\n",
      "Epoch 5 Loss 0.5619 Accuracy 0.9272\n",
      "Time taken for 1 epoch: 141.86448049545288 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [14:47<1:45:11, 143.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss 0.5195 Accuracy 0.9291\n",
      "Time taken for 1 epoch: 140.7785406112671 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [17:08<1:42:09, 142.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss 0.4837 Accuracy 0.9309\n",
      "Time taken for 1 epoch: 140.74905443191528 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [19:29<1:39:24, 142.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss 0.4535 Accuracy 0.9327\n",
      "Time taken for 1 epoch: 140.826345205307 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [21:50<1:36:46, 141.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss 0.4249 Accuracy 0.9343\n",
      "Time taken for 1 epoch: 140.79870438575745 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [24:11<1:34:26, 141.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint for epoch 11 at transformer_training_artifacts/training_checkpoints/transformer_2024-04-03-04-28_256_512_4_8_0.1_20394_32926_50_32_325/ckpt-2\n",
      "Epoch 10 Loss 0.3981 Accuracy 0.9360\n",
      "Time taken for 1 epoch: 141.75087690353394 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [26:32<1:31:54, 141.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Loss 0.3724 Accuracy 0.9377\n",
      "Time taken for 1 epoch: 140.8082935810089 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [28:53<1:29:26, 141.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Loss 0.3489 Accuracy 0.9395\n",
      "Time taken for 1 epoch: 140.78357529640198 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [31:14<1:26:59, 141.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Loss 0.3265 Accuracy 0.9414\n",
      "Time taken for 1 epoch: 140.7388916015625 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [33:34<1:24:34, 140.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Loss 0.3004 Accuracy 0.9441\n",
      "Time taken for 1 epoch: 140.70149040222168 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [35:56<1:22:20, 141.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint for epoch 16 at transformer_training_artifacts/training_checkpoints/transformer_2024-04-03-04-28_256_512_4_8_0.1_20394_32926_50_32_325/ckpt-3\n",
      "Epoch 15 Loss 0.2718 Accuracy 0.9476\n",
      "Time taken for 1 epoch: 141.6537425518036 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [38:17<1:19:54, 141.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Loss 0.2430 Accuracy 0.9515\n",
      "Time taken for 1 epoch: 140.67940068244934 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [40:37<1:17:30, 140.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Loss 0.2166 Accuracy 0.9553\n",
      "Time taken for 1 epoch: 140.7104253768921 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [42:58<1:15:07, 140.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Loss 0.1933 Accuracy 0.9589\n",
      "Time taken for 1 epoch: 140.72883868217468 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [45:19<1:12:45, 140.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Loss 0.1733 Accuracy 0.9621\n",
      "Time taken for 1 epoch: 140.73692226409912 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [47:40<1:10:31, 141.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint for epoch 21 at transformer_training_artifacts/training_checkpoints/transformer_2024-04-03-04-28_256_512_4_8_0.1_20394_32926_50_32_325/ckpt-4\n",
      "Epoch 20 Loss 0.1546 Accuracy 0.9653\n",
      "Time taken for 1 epoch: 141.6169149875641 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [50:01<1:08:08, 140.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Loss 0.1391 Accuracy 0.9679\n",
      "Time taken for 1 epoch: 140.74676966667175 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [52:22<1:05:45, 140.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Loss 0.1253 Accuracy 0.9705\n",
      "Time taken for 1 epoch: 140.71928143501282 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [54:43<1:03:23, 140.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Loss 0.1127 Accuracy 0.9729\n",
      "Time taken for 1 epoch: 140.77496910095215 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [57:03<1:01:01, 140.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Loss 0.1029 Accuracy 0.9748\n",
      "Time taken for 1 epoch: 140.74073457717896 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [59:25<58:46, 141.07s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint for epoch 26 at transformer_training_artifacts/training_checkpoints/transformer_2024-04-03-04-28_256_512_4_8_0.1_20394_32926_50_32_325/ckpt-5\n",
      "Epoch 25 Loss 0.0923 Accuracy 0.9770\n",
      "Time taken for 1 epoch: 141.65796422958374 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [1:01:46<56:23, 140.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Loss 0.0853 Accuracy 0.9785\n",
      "Time taken for 1 epoch: 140.707510471344 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [1:04:07<54:00, 140.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Loss 0.0783 Accuracy 0.9800\n",
      "Time taken for 1 epoch: 140.7250828742981 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [1:06:27<51:39, 140.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Loss 0.0725 Accuracy 0.9814\n",
      "Time taken for 1 epoch: 140.7936646938324 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [1:08:48<49:16, 140.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Loss 0.0668 Accuracy 0.9826\n",
      "Time taken for 1 epoch: 140.68007016181946 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [1:11:10<47:01, 141.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint for epoch 31 at transformer_training_artifacts/training_checkpoints/transformer_2024-04-03-04-28_256_512_4_8_0.1_20394_32926_50_32_325/ckpt-6\n",
      "Epoch 30 Loss 0.0621 Accuracy 0.9837\n",
      "Time taken for 1 epoch: 141.66960954666138 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [1:13:30<44:38, 140.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Loss 0.0581 Accuracy 0.9846\n",
      "Time taken for 1 epoch: 140.751971244812 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [1:15:51<42:16, 140.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Loss 0.0547 Accuracy 0.9855\n",
      "Time taken for 1 epoch: 140.86904096603394 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [1:18:12<39:54, 140.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Loss 0.0514 Accuracy 0.9863\n",
      "Time taken for 1 epoch: 140.6739809513092 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [1:20:33<37:32, 140.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Loss 0.0482 Accuracy 0.9870\n",
      "Time taken for 1 epoch: 140.6664891242981 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [1:22:54<35:15, 141.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint for epoch 36 at transformer_training_artifacts/training_checkpoints/transformer_2024-04-03-04-28_256_512_4_8_0.1_20394_32926_50_32_325/ckpt-7\n",
      "Epoch 35 Loss 0.0461 Accuracy 0.9876\n",
      "Time taken for 1 epoch: 141.63100361824036 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [1:25:15<32:53, 140.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Loss 0.0435 Accuracy 0.9882\n",
      "Time taken for 1 epoch: 140.712096452713 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [1:27:36<30:31, 140.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Loss 0.0409 Accuracy 0.9889\n",
      "Time taken for 1 epoch: 140.69272208213806 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [1:29:56<28:09, 140.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Loss 0.0389 Accuracy 0.9895\n",
      "Time taken for 1 epoch: 140.7165961265564 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [1:32:17<25:48, 140.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Loss 0.0368 Accuracy 0.9900\n",
      "Time taken for 1 epoch: 140.7060215473175 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [1:34:39<23:30, 141.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint for epoch 41 at transformer_training_artifacts/training_checkpoints/transformer_2024-04-03-04-28_256_512_4_8_0.1_20394_32926_50_32_325/ckpt-8\n",
      "Epoch 40 Loss 0.0353 Accuracy 0.9903\n",
      "Time taken for 1 epoch: 141.69147634506226 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [1:37:00<21:08, 140.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Loss 0.0335 Accuracy 0.9908\n",
      "Time taken for 1 epoch: 140.71352815628052 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [1:39:20<18:47, 140.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Loss 0.0320 Accuracy 0.9912\n",
      "Time taken for 1 epoch: 140.71199584007263 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [1:41:41<16:25, 140.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Loss 0.0307 Accuracy 0.9916\n",
      "Time taken for 1 epoch: 140.70782446861267 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [1:44:02<14:04, 140.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Loss 0.0294 Accuracy 0.9919\n",
      "Time taken for 1 epoch: 140.68632888793945 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [1:46:23<11:45, 141.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint for epoch 46 at transformer_training_artifacts/training_checkpoints/transformer_2024-04-03-04-28_256_512_4_8_0.1_20394_32926_50_32_325/ckpt-9\n",
      "Epoch 45 Loss 0.0281 Accuracy 0.9923\n",
      "Time taken for 1 epoch: 141.67250180244446 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [1:48:44<09:23, 140.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Loss 0.0272 Accuracy 0.9925\n",
      "Time taken for 1 epoch: 140.690988779068 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [1:51:05<07:02, 140.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Loss 0.0258 Accuracy 0.9929\n",
      "Time taken for 1 epoch: 140.65724110603333 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [1:53:25<04:41, 140.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Loss 0.0250 Accuracy 0.9931\n",
      "Time taken for 1 epoch: 140.69540238380432 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [1:55:46<02:20, 140.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Loss 0.0240 Accuracy 0.9935\n",
      "Time taken for 1 epoch: 140.638023853302 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [1:58:08<00:00, 141.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint for epoch 51 at transformer_training_artifacts/training_checkpoints/transformer_2024-04-03-04-28_256_512_4_8_0.1_20394_32926_50_32_325/ckpt-10\n",
      "Epoch 50 Loss 0.0229 Accuracy 0.9937\n",
      "Time taken for 1 epoch: 141.67951703071594 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Training \n",
    "for epoch in tqdm(range(1, EPOCHS+1)):\n",
    "    start = time.time()\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    current_batch_index = 0\n",
    "\n",
    "    # iterate through the dataset in batches of batch_size\n",
    "    for i in (range(int(len(target_sentences)/batch_size))):\n",
    "        # get the input and target batch\n",
    "        target_batch = tf.convert_to_tensor(np.array(target_sentences[current_batch_index:current_batch_index+batch_size]),dtype=tf.int64)\n",
    "        input_batch = tf.convert_to_tensor(np.array(inp_sentences[current_batch_index:current_batch_index+batch_size]),dtype=tf.int64)\n",
    "\n",
    "        # English --> Telugu Translation\n",
    "#         input_batch = tf.convert_to_tensor(np.array(target_sentences[current_batch_index:current_batch_index+batch_size]),dtype=tf.int64)\n",
    "#         target_batch = tf.convert_to_tensor(np.array(inp_sentences[current_batch_index:current_batch_index+batch_size]),dtype=tf.int64)\n",
    "\n",
    "        current_batch_index = current_batch_index + batch_size\n",
    "        # call the train_step function to train the model using the current batch\n",
    "        train_step(input_batch, target_batch)\n",
    "\n",
    "    if (epoch) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                             ckpt_save_path))\n",
    "\n",
    "    # print the epoch loss and accuracy after iterating through the dataset\n",
    "    print (f'Epoch {epoch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}') \n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n",
    "\n",
    "# Save the Tokenizer after the Model Training is successful (To reduce the model artifacts if model training is failed)\n",
    "save_the_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T06:28:30.751654Z",
     "iopub.status.busy": "2024-04-03T06:28:30.751286Z",
     "iopub.status.idle": "2024-04-03T06:28:30.757891Z",
     "shell.execute_reply": "2024-04-03T06:28:30.756829Z",
     "shell.execute_reply.started": "2024-04-03T06:28:30.751625Z"
    }
   },
   "outputs": [],
   "source": [
    "# ### Training \n",
    "# for epoch in tqdm(range(51, 101)):\n",
    "#     start = time.time()\n",
    "#     # Reset the metrics at the start of the next epoch\n",
    "#     train_loss.reset_states()\n",
    "#     train_accuracy.reset_states()\n",
    "#     current_batch_index = 0\n",
    "\n",
    "#     # iterate through the dataset in batches of batch_size\n",
    "#     for i in (range(int(len(target_sentences)/batch_size))):\n",
    "#         # get the input and target batch\n",
    "#         target_batch = tf.convert_to_tensor(np.array(target_sentences[current_batch_index:current_batch_index+batch_size]),dtype=tf.int64)\n",
    "#         input_batch = tf.convert_to_tensor(np.array(inp_sentences[current_batch_index:current_batch_index+batch_size]),dtype=tf.int64)\n",
    "\n",
    "#         # English --> Telugu Translation\n",
    "# #         input_batch = tf.convert_to_tensor(np.array(target_sentences[current_batch_index:current_batch_index+batch_size]),dtype=tf.int64)\n",
    "# #         target_batch = tf.convert_to_tensor(np.array(inp_sentences[current_batch_index:current_batch_index+batch_size]),dtype=tf.int64)\n",
    "\n",
    "#         current_batch_index = current_batch_index + batch_size\n",
    "#         # call the train_step function to train the model using the current batch\n",
    "#         train_step(input_batch, target_batch)\n",
    "\n",
    "#     if (epoch) % 5 == 0:\n",
    "#         ckpt_save_path = ckpt_manager.save()\n",
    "#         print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "#                                                              ckpt_save_path))\n",
    "\n",
    "#     # print the epoch loss and accuracy after iterating through the dataset\n",
    "#     print (f'Epoch {epoch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}') \n",
    "#     print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n",
    "\n",
    "# # Save the Tokenizer after the Model Training is successful (To reduce the model artifacts if model training is failed)\n",
    "# save_the_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T06:28:33.932184Z",
     "iopub.status.busy": "2024-04-03T06:28:33.931769Z",
     "iopub.status.idle": "2024-04-03T06:28:33.940036Z",
     "shell.execute_reply": "2024-04-03T06:28:33.939084Z",
     "shell.execute_reply.started": "2024-04-03T06:28:33.932154Z"
    }
   },
   "outputs": [],
   "source": [
    "# ### Training \n",
    "# for epoch in tqdm(range(101, 121)):\n",
    "#     start = time.time()\n",
    "#     # Reset the metrics at the start of the next epoch\n",
    "#     train_loss.reset_states()\n",
    "#     train_accuracy.reset_states()\n",
    "#     current_batch_index = 0\n",
    "\n",
    "#     # iterate through the dataset in batches of batch_size\n",
    "#     for i in (range(int(len(target_sentences)/batch_size))):\n",
    "#         # get the input and target batch\n",
    "#         target_batch = tf.convert_to_tensor(np.array(target_sentences[current_batch_index:current_batch_index+batch_size]),dtype=tf.int64)\n",
    "#         input_batch = tf.convert_to_tensor(np.array(inp_sentences[current_batch_index:current_batch_index+batch_size]),dtype=tf.int64)\n",
    "\n",
    "#         # English --> Telugu Translation\n",
    "# #         input_batch = tf.convert_to_tensor(np.array(target_sentences[current_batch_index:current_batch_index+batch_size]),dtype=tf.int64)\n",
    "# #         target_batch = tf.convert_to_tensor(np.array(inp_sentences[current_batch_index:current_batch_index+batch_size]),dtype=tf.int64)\n",
    "\n",
    "#         current_batch_index = current_batch_index + batch_size\n",
    "#         # call the train_step function to train the model using the current batch\n",
    "#         train_step(input_batch, target_batch)\n",
    "\n",
    "#     if (epoch) % 5 == 0:\n",
    "#         ckpt_save_path = ckpt_manager.save()\n",
    "#         print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "#                                                              ckpt_save_path))\n",
    "\n",
    "#     # print the epoch loss and accuracy after iterating through the dataset\n",
    "#     print (f'Epoch {epoch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}') \n",
    "#     print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n",
    "\n",
    "# # Save the Tokenizer after the Model Training is successful (To reduce the model artifacts if model training is failed)\n",
    "# save_the_tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Greedy Translation\n",
    "\n",
    "**Translate Helper Function**\n",
    "\n",
    "**This function takes source language sentence as input and generates a translated sentence in the target language.using the following steps:**\n",
    "\n",
    "1.  The input sentence is preprocessed by adding start and end of sentence markers and converting it to a list because of TensorFlow's tokenizer.\n",
    "\n",
    "2.  The preprocessed sentence is vectorized and padded to a fixed length of 30 using the target language tokenizer.\n",
    "\n",
    "3. The start of the decoder input is tokenized and converted to a tensor using the target language tokenizer.\n",
    "\n",
    "4. The function then enters a loop that generates predictions for the current input sequence, selects the last word from the seq_len dimension, gets the predicted word ID by taking the argmax of the predictions, concatenates the predicted ID to the output which is given to the decoder as its input, and checks if the predicted ID is equal to the end token. If the predicted ID is equal to the end token, the function returns the decoder input, otherwise the loop continues.\n",
    "\n",
    "5. If the loop completes without finding the end token, the function returns the translated sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T06:28:39.924750Z",
     "iopub.status.busy": "2024-04-03T06:28:39.924362Z",
     "iopub.status.idle": "2024-04-03T06:28:39.935766Z",
     "shell.execute_reply": "2024-04-03T06:28:39.934779Z",
     "shell.execute_reply.started": "2024-04-03T06:28:39.924722Z"
    }
   },
   "outputs": [],
   "source": [
    "maxlen = MAX_LEN\n",
    "def translate_helper(sentence):\n",
    "    \"\"\"\n",
    "    Evaluate function that generates a translated sentence from the given input sentence.\n",
    "\n",
    "    Args:\n",
    "    sentence (str): The input sentence in the source language.\n",
    "\n",
    "    Returns:\n",
    "    A tensor representing the translated sentence.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Preprocess the input sentence\n",
    "    sentence = preprocess_text(sentence[0], is_telugu=True)\n",
    "\n",
    "    sentence = '<start> ' + sentence + ' <end>' # Add start and end of sentence markers\n",
    "    sentence = [sentence] # Convert sentence to list because of TensorFlow's tokenizer\n",
    "    \n",
    "    # Vectorize and pad the sentence\n",
    "    sentence = tokenizer_inp.texts_to_sequences(sentence)\n",
    "    sentence = pad_sequences(sentence, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "    input = tf.convert_to_tensor(np.array(sentence),dtype=tf.int64) # Convert input to tensor\n",
    "    \n",
    "    # Tokenize the start of the decoder input and convert it to a tensor\n",
    "    decoder_input = tokenizer_tar.texts_to_sequences(['<start>'])\n",
    "    decoder_input = tf.convert_to_tensor(np.array(decoder_input), dtype=tf.int64)\n",
    "    \n",
    "    # Generate the translated sentence\n",
    "    for i in range(maxlen):\n",
    "        # Create masks for the encoder, decoder, and combined\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(input, decoder_input)\n",
    "        # Generate predictions for the current input sequence\n",
    "        predictions, _ = transformer(input, decoder_input,False,enc_padding_mask,combined_mask, dec_padding_mask)\n",
    "        # Select the last word from the seq_len dimension\n",
    "        predictions = predictions[: ,-1:, :] \n",
    "        # Get the predicted word ID by taking the argmax of the predictions\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int64)\n",
    "        \n",
    "        # If the predicted ID is equal to the end token, return the decoder input\n",
    "        if predicted_id == tokenizer_tar.texts_to_sequences(['<end>']):\n",
    "            return tf.squeeze(decoder_input, axis=0)\n",
    "        \n",
    "        # Concatenate the predicted ID to the output which is given to the decoder\n",
    "        # as its input.\n",
    "        decoder_input = tf.concat([decoder_input, predicted_id], axis=1)\n",
    "    \n",
    "    # Return the translated sentence\n",
    "    return tf.squeeze(decoder_input, axis=0)\n",
    "\n",
    "def translate(sentence):\n",
    "    \"\"\"\n",
    "    Translate function that generates a translation for the given input sentence.\n",
    "\n",
    "    Args:\n",
    "    sentence (str): The input sentence in the source language.\n",
    "\n",
    "    Returns:\n",
    "    None.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert sentence to list because our evaluate function requires lists\n",
    "    sentence = [sentence]\n",
    "    \n",
    "    # Print the input sentence\n",
    "    print(f'Input sentence: {sentence[0]}')\n",
    "    print()\n",
    "    \n",
    "    # Generate the translated sentence\n",
    "    result = (translate_helper(sentence)).tolist()\n",
    "    \n",
    "    # Convert the result tensor to a list of IDs and remove start and end of sentence markers\n",
    "    predicted_ids = [i for i in result if i != tokenizer_tar.texts_to_sequences(['<start>'])[0][0]\n",
    "                     and i != tokenizer_tar.texts_to_sequences(['<end>'])[0][0]]\n",
    "    \n",
    "    # Convert the predicted IDs to a list of words\n",
    "    predicted_sentence = tokenizer_tar.sequences_to_texts([predicted_ids])\n",
    "    \n",
    "    # Print the predicted translation\n",
    "    print(f'Translation: {predicted_sentence[0]}')\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam Search Translation\n",
    "- BEAM Search Inference Code - Beam-width (k) is a hyperparameter, which helps us to choose top-k elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T06:29:07.048872Z",
     "iopub.status.busy": "2024-04-03T06:29:07.048391Z",
     "iopub.status.idle": "2024-04-03T06:29:07.071017Z",
     "shell.execute_reply": "2024-04-03T06:29:07.069875Z",
     "shell.execute_reply.started": "2024-04-03T06:29:07.048830Z"
    }
   },
   "outputs": [],
   "source": [
    "# BEAM Search Code\n",
    "\n",
    "beam_width = 5  # Define the beam width\n",
    "\n",
    "def translate_helper_beam_search(sentence):\n",
    "    \"\"\"\n",
    "    Evaluate function that generates a translated sentence from the given input sentence using beam search.\n",
    "\n",
    "    Args:\n",
    "    sentence (str): The input sentence in the source language.\n",
    "\n",
    "    Returns:\n",
    "    A tensor representing the translated sentence.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Preprocess the input sentence\n",
    "    sentence = preprocess_text(sentence[0], is_telugu=True)\n",
    "\n",
    "    sentence = '<start> ' + sentence + ' <end>' # Add start and end of sentence markers\n",
    "    sentence = [sentence] # Convert sentence to list because of TensorFlow's tokenizer\n",
    "    \n",
    "    # Vectorize and pad the sentence\n",
    "    sentence = tokenizer_inp.texts_to_sequences(sentence)\n",
    "    sentence = pad_sequences(sentence, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "    input = tf.convert_to_tensor(np.array(sentence), dtype=tf.int64) # Convert input to tensor\n",
    "    \n",
    "    # Tokenize the start of the decoder input and convert it to a tensor\n",
    "    decoder_input = tokenizer_tar.texts_to_sequences(['<start>'])\n",
    "    decoder_input = tf.convert_to_tensor(np.array(decoder_input), dtype=tf.int64)\n",
    "    \n",
    "    # Initialize the beam search candidates\n",
    "    candidates = [(decoder_input, 0)]  # List of (decoder_input, score) tuples\n",
    "    \n",
    "    # Generate the translated sentence using beam search\n",
    "    for _ in range(maxlen):\n",
    "        new_candidates = []\n",
    "        for decoder_input, score in candidates:\n",
    "            # Create masks for the encoder, decoder, and combined\n",
    "            enc_padding_mask, combined_mask, dec_padding_mask = create_masks(input, decoder_input)\n",
    "            # Generate predictions for the current input sequence\n",
    "            predictions, _ = transformer(input, decoder_input, False, enc_padding_mask, combined_mask, dec_padding_mask)\n",
    "            # Select the last word from the seq_len dimension\n",
    "            predictions = predictions[:, -1:, :]\n",
    "            # Get the top beam_width predictions and their indices\n",
    "            topk_probs, topk_ids = tf.nn.top_k(tf.squeeze(predictions, axis=1), k=beam_width)\n",
    "            for i in range(beam_width):\n",
    "                new_decoder_input = tf.concat([decoder_input, tf.expand_dims(tf.expand_dims(tf.cast(topk_ids[0][i], tf.int64), axis=0), axis=0)], axis=1)\n",
    "                new_score = score + tf.math.log(topk_probs[0][i]).numpy()\n",
    "                new_candidates.append((new_decoder_input, new_score))\n",
    "\n",
    "#             for i in range(beam_width):\n",
    "#                 new_decoder_input = tf.concat([decoder_input, tf.expand_dims(topk_ids[0][i], axis=0)], axis=1)\n",
    "#                 new_score = score + tf.math.log(topk_probs[0][i]).numpy()\n",
    "#                 new_candidates.append((new_decoder_input, new_score))\n",
    "        \n",
    "    \n",
    "        # Select the top beam_width candidates\n",
    "        candidates = sorted(new_candidates, key=lambda x: x[1], reverse=True)[:beam_width]\n",
    "        \n",
    "        # Check if any of the candidates end with the end token\n",
    "        for candidate, _ in candidates:\n",
    "            if candidate[0][-1] == tokenizer_tar.texts_to_sequences(['<end>']):\n",
    "                return tf.squeeze(candidate, axis=0)\n",
    "    \n",
    "    # Return the translated sentence with the highest score among the candidates\n",
    "    return tf.squeeze(candidates[0][0], axis=0)\n",
    "\n",
    "\n",
    "def translate_beam(sentence):\n",
    "    \"\"\"\n",
    "    Translate function that generates a translation for the given input sentence.\n",
    "\n",
    "    Args:\n",
    "    sentence (str): The input sentence in the source language.\n",
    "\n",
    "    Returns:\n",
    "    None.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert sentence to list because our evaluate function requires lists\n",
    "    sentence = [sentence]\n",
    "    \n",
    "    # Print the input sentence\n",
    "    print(f'Input sentence: {sentence[0]}')\n",
    "    print()\n",
    "    \n",
    "    # Generate the translated sentence\n",
    "    result = (translate_helper_beam_search(sentence)).tolist()\n",
    "    \n",
    "    # Convert the result tensor to a list of IDs and remove start and end of sentence markers\n",
    "    predicted_ids = [i for i in result if i != tokenizer_tar.texts_to_sequences(['<start>'])[0][0]\n",
    "                     and i != tokenizer_tar.texts_to_sequences(['<end>'])[0][0]]\n",
    "    \n",
    "    # Convert the predicted IDs to a list of words\n",
    "    predicted_sentence = tokenizer_tar.sequences_to_texts([predicted_ids])\n",
    "    \n",
    "    # Print the predicted translation\n",
    "    print(f'Translation: {predicted_sentence[0]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T06:46:46.968725Z",
     "iopub.status.busy": "2024-04-03T06:46:46.968362Z",
     "iopub.status.idle": "2024-04-03T06:47:01.309552Z",
     "shell.execute_reply": "2024-04-03T06:47:01.308627Z",
     "shell.execute_reply.started": "2024-04-03T06:46:46.968696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy Search Output:\n",
      "\n",
      "Input sentence: climatic phenomenon that occurs when the waters of the pacific ocean near the equator get warmer\n",
      "\n",
      "Translation: సమీపంలో ఉన్న పసిఫిక్ జలాలు సగటు కంటే వెచ్చగా ఉన్నప్పుడు సంభవించే వాతావరణ దృగ్విషయం ఎల్ ఈ వేడెక్కడం ప్రతి కొన్ని సంవత్సరాలకు సంభవిస్తుంది\n",
      "\n",
      "\n",
      "Beam Search Output:\n",
      "Input sentence: climatic phenomenon that occurs when the waters of the pacific ocean near the equator get warmer\n",
      "\n",
      "Translation: సంక్షోభం మధ్య పెరుగుతున్న వాతావరణం ఏమిటి? సుమారు మంది జరిగింది\n"
     ]
    }
   ],
   "source": [
    "sentence = \"climatic phenomenon that occurs when the waters of the pacific ocean near the equator get warmer\"\n",
    "print(f\"Greedy Search Output:\\n\")\n",
    "translate(sentence)\n",
    "print(f\"\\n\\nBeam Search Output:\")\n",
    "translate_beam(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T06:47:01.311767Z",
     "iopub.status.busy": "2024-04-03T06:47:01.311425Z",
     "iopub.status.idle": "2024-04-03T06:47:19.941450Z",
     "shell.execute_reply": "2024-04-03T06:47:19.940467Z",
     "shell.execute_reply.started": "2024-04-03T06:47:01.311734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy Search Output:\n",
      "\n",
      "Input sentence: technology has drastically transformed the way we work allowing for increased efficiency flexibility\n",
      "\n",
      "Translation: పెరిగిన సాంకేతిక పరిజ్ఞానం వైద్య ప్రపంచంలో చాలా ఇప్పుడు చాలా ఇప్పుడు రొటీన్ మరియు పునరావృత పనులను ఆటోమేట్ చేయగలవు ఉత్పాదకతను పెంచుతాయి మరియు సమయాన్ని ఆదా చేస్తాయి\n",
      "\n",
      "\n",
      "Beam Search Output:\n",
      "Input sentence: technology has drastically transformed the way we work allowing for increased efficiency flexibility\n",
      "\n",
      "Translation: పెరిగిన భద్రత సెల్ఫ్ డ్రైవింగ్ కార్లు సిస్టమ్స్ వంటి అధునాతన సాంకేతిక పరిజ్ఞానం మెరుగుపరచడం\n"
     ]
    }
   ],
   "source": [
    "sentence = \"technology has drastically transformed the way we work allowing for increased efficiency flexibility\"\n",
    "print(f\"Greedy Search Output:\\n\")\n",
    "translate(sentence)\n",
    "print(f\"\\n\\nBeam Search Output:\")\n",
    "translate_beam(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T06:47:19.943104Z",
     "iopub.status.busy": "2024-04-03T06:47:19.942717Z",
     "iopub.status.idle": "2024-04-03T06:47:45.986732Z",
     "shell.execute_reply": "2024-04-03T06:47:45.985830Z",
     "shell.execute_reply.started": "2024-04-03T06:47:19.943060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy Search Output:\n",
      "\n",
      "Input sentence: with the advent of computer systems internet connectivity and digital tools work is no longer confined to traditional office spaces \n",
      "\n",
      "Translation: పరికరాలు మరియు డిజిటల్ నియంత్రించడం మరియు సంగీతాన్ని ప్లే చేయడం వంటి వివిధ పనులకు ఉపయోగించే కదలికలను పరిశీలించడానికి ఉపయోగిస్తారు. ఈ పరికరాలు కంప్యూటర్లు ఎలా యాక్సెస్ చేయగల వీలు\n",
      "\n",
      "\n",
      "Beam Search Output:\n",
      "Input sentence: with the advent of computer systems internet connectivity and digital tools work is no longer confined to traditional office spaces \n",
      "\n",
      "Translation: పరికరాలు ఇవి డిజిటల్ చిత్రాలు మరియు వీడియోలను గుర్తించడానికి మరియు ఇంటర్నెట్ ను ఉపయోగిస్తాయి. ఈ పరికరాలు కంప్యూటర్లు ఎలా సంకేతాలను పంపడం\n"
     ]
    }
   ],
   "source": [
    "sentence = \"with the advent of computer systems internet connectivity and digital tools work is no longer confined to traditional office spaces \"\n",
    "print(f\"Greedy Search Output:\\n\")\n",
    "translate(sentence)\n",
    "print(f\"\\n\\nBeam Search Output:\")\n",
    "translate_beam(sentence)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1520310,
     "sourceId": 2510329,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4712489,
     "sourceId": 8002266,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4722056,
     "sourceId": 8014956,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
